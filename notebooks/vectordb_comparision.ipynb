{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Vector DB comparision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## [Vector DB Dashboard](https://superlinked.com/vector-db-comparison) -> Click to get more information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "|      **Feature**       |      **FAISS**      |                       **ChromaDB**                        |      **Pinecone**      |                          **Weaviate**                          |                    **Qdrant**                    |           LanceDB            |\n",
    "| :--------------------: | :-----------------: | :-------------------------------------------------------: | :--------------------: | :------------------------------------------------------------: | :----------------------------------------------: | :--------------------------: |\n",
    "|        **Type**        |       Library       |                       Library + DB                        |    Managed Cloud DB    |                        Managed DB + OSS                        |                 Managed DB + OSS                 |       Managed DB + OSS       |\n",
    "|      **Hosting**       |        Local        |                Local (some cloud support)                 |       Cloud-only       |                       Cloud & Self-host                        |                Cloud & Self-host                 |      Cloud & Self-host       |\n",
    "| **Persistant Storage** |   No (in-memory)    |                            Yes                            |          Yes           |                              Yes                               |                       Yes                        |           Yes (s3)           |\n",
    "|    **Scalability**     |       Manual        |                          Limited                          |      Auto-scaling      |                          Auto-scaling                          |                   Auto-scaling                   |         Auto-scaling         |\n",
    "|     **API Access**     |     No REST API     |                        Python API                         |     REST/gRPC API      |                         REST/gRPC API                          |                  REST/gRPC API                   |       Pandas Style API       |\n",
    "|  **Indexing Option**   | IVF, HNSW, PQ, Flat |                        HNSW, SPANN                        |      Proprietery       |                    HNSW, Flat, IVF, Flat-BQ                    |                  HNSW, IVF, PQ                   |        HNSW, IVF, PQ         |\n",
    "|       **BM-25**        |         No          |                            No                             |           No           |                              Yes                               |                        No                        |             Yes              |\n",
    "|   **Hybrid search**    |         No          |                            No                             |          Yes           |                              Yes                               |                       Yes                        |             Yes              |\n",
    "| **Metadata Filtering** |       Manual        |                         Built-in                          |        Built-in        |                            Built-in                            |                     Built-in                     |      Built-in (limited)      |\n",
    "|    **Replication**     |         No          |                            No                             |          Yes           |                              Yes                               |                       Yes                        |              NA              |\n",
    "| **Embeddings Storage** |    Vectors only     |              Vectors + Metadata + Documents               |   Vectors + Metadata   |                  Vectors + Metadata + Schema                   |       Vectors + Payload (Custom metadata)        |       tabular + vector       |\n",
    "|    **Integrations**    |       Custom        |                  Langchain, Lllamaindex                   | Langchain, Lllamaindex |                     Langchain, Lllamaindex                     |              Langchain, Lllamaindex              |    Langchain, Lllamaindex    |\n",
    "|      **License**       |         MIT         |                        Apache 2.0                         |    Proprietery SaaS    |                              BSD                               |                    Apache 2.0                    |          Apache 2.0          |\n",
    "|      **Best For**      |  Fast local search  |                   Embedding + metadata                    |    Production Saas     |                Knowledge graph & vector search                 |           Vector Search with filtering           | Tabular data + Vector search |\n",
    "|    **Docker image**    |         No          | [chromadb](https://hub.docker.com/r/chromadb/chroma/tags) |           NA           | [weaviate](https://hub.docker.com/r/semitechnologies/weaviate) | [qdrant](https://hub.docker.com/r/qdrant/qdrant) |              NA              |\n",
    "|    **Dev Language**    |         C++         |                           rust                            |          rust          |                               go                               |                       rust                       |             rust             |\n",
    "|    **Multi-tenant**    |         No          |                            Yes                            |  Yes (via namespace)   |                              Yes                               |          Yes (via collection/metadata)           |              No              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Comparing different vector db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Step 1 - Prepare test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "sentences = [\n",
    "\t\"Artificial intelligence is transforming modern healthcare through diagnostic \\\n",
    "\ttools.\",\n",
    "\t\"Machine learning algorithms can predict patient outcomes with high accuracy.\",\n",
    "\t\"Neural networks require large amounts of training data to be effective.\",\n",
    "\t\"Cloud computing enables scalable AI deployment across industries.\",\n",
    "\t\"Natural language processing allows computers to understand human speech.\",\n",
    "\t\"Deep learning models excel at image recognition tasks.\",\n",
    "\t\"Data privacy remains a major concern in AI implementation.\",\n",
    "\t\"Quantum computing promises to revolutionize complex calculations.\",\n",
    "\t\"Robotics automation is changing manufacturing processes worldwide.\",\n",
    "\t\"Computer vision systems can identify objects in real-time video.\",\n",
    "\t\"Ethical AI development requires careful consideration of bias.\",\n",
    "\t\"The Internet of Things connects everyday devices to the cloud.\",\n",
    "\t\"Blockchain technology provides secure decentralized transactions.\",\n",
    "\t\"5G networks enable faster data transfer for mobile applications.\",\n",
    "\t\"Virtual reality creates immersive digital experiences for users.\",\n",
    "\t\"Cybersecurity threats continue to evolve with advancing technology.\",\n",
    "\t\"Big data analytics helps businesses make informed decisions.\",\n",
    "\t\"Autonomous vehicles use sensors and AI to navigate roads safely.\",\n",
    "\t\"Edge computing processes data closer to the source for reduced latency.\",\n",
    "\t\"Augmented reality overlays digital information onto the real world.\",\n",
    "\t\"Python is the most popular programming language for data science.\",\n",
    "\t\"Reinforcement learning allows AI to learn through trial and error.\",\n",
    "\t\"Semiconductor chips are essential components in all computing devices.\",\n",
    "\t\"Digital transformation affects every industry in the modern economy.\",\n",
    "\t\"AI ethics committees are being formed to guide responsible development.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "\t\"AI in healthcare\",\n",
    "\t\"Machine learning applications\",\n",
    "\t\"Technology security concerns\",\n",
    "\t\"Neural networks and data requirements\",\n",
    "\t\"Real-time computer vision systems\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import UTC, datetime\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# load environment variables from a .env file (if present)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "EURI_API_KEY = os.getenv(\"EURI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "WEAVIATE_REST_END_POINT = os.getenv(\"WEAVIATE_REST_ENDPOINT\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text: str) -> np.ndarray:\n",
    "\turl = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
    "\theaders = {\n",
    "\t\t\"Content-Type\": \"application/json\",\n",
    "\t\t\"Authorization\": f\"Bearer {EURI_API_KEY}\",\n",
    "\t}\n",
    "\tpayload = {\"input\": text, \"model\": \"text-embedding-3-small\"}\n",
    "\n",
    "\tresponse = requests.post(url, headers=headers, json=payload, timeout=30)\n",
    "\tdata = response.json()\n",
    "\n",
    "\treturn np.array(data[\"data\"][0][\"embedding\"], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The weather is sunny today.\"\n",
    "\n",
    "embedding = generate_embeddings(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"embedding shape: {embedding.shape} and embedding type: {embedding.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for i in sentences:\n",
    "\temb = generate_embeddings(text=i)\n",
    "\tembeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_array = np.vstack(embeddings)\n",
    "embeddings_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embeddings_array.shape[1]\n",
    "dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Running in FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(dimension)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(embeddings_array)\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = queries[0]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = generate_embeddings(text=query).reshape(1, -1)\n",
    "query_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, indices = index.search(query_vec, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "\tf\"Query: {query}\\n\"\n",
    "\tf\"Top 2 most similar sentences:\\n\"\n",
    "\tf\"{sentences[indices[0][0]]}\\n\"\n",
    "\tf\"{sentences[indices[0][1]]}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "faiss.write_index(index, \"../data/faiss_index.faiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Chroma DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"../data/chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_list = chroma_client.list_collections()\n",
    "if len(collection_list) > 0:\n",
    "\tprint(collection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(name=\"chroma_db_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_collection = chroma_client.create_collection(\n",
    "\tname=\"chroma_db_test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_collection.add(\n",
    "\tdocuments=sentences,\n",
    "\tembeddings=embeddings_array,\n",
    "\tids=[f\"rec_{i}\" for i in range(len(sentences))],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = generate_embeddings(text=query).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chroma_collection.query(query_embeddings=query_vec, n_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chroma_results_detailed(result, query_text=None):\n",
    "\t\"\"\"\n",
    "\tDetailed formatting with metadata support.\n",
    "\t\"\"\"\n",
    "\tif query_text:\n",
    "\t\tprint(f\"🔍 QUERY: '{query_text}'\")\n",
    "\t\tprint(\"=\" * 80)\n",
    "\n",
    "\tdocuments = result[\"documents\"][0]\n",
    "\tdistances = result[\"distances\"][0]\n",
    "\tids = result[\"ids\"][0]\n",
    "\tmetadatas = (\n",
    "\t\tresult[\"metadatas\"][0] if result[\"metadatas\"] else [None] * len(documents)\n",
    "\t)\n",
    "\n",
    "\tprint(f\"📊 Found {len(documents)} results (lower distance = more similar)\\n\")\n",
    "\n",
    "\tfor i, (doc_id, document, distance, metadata) in enumerate(\n",
    "\t\tzip(ids, documents, distances, metadatas, strict=False)\n",
    "\t):\n",
    "\t\tprint(f\"🏆 RANK {i + 1} | Distance: {distance:.4f} | ID: {doc_id}\")\n",
    "\t\tprint(f\"📄 Document: {document}\")\n",
    "\t\tif metadata:\n",
    "\t\t\tprint(f\"📋 Metadata: {metadata}\")\n",
    "\t\tprint(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chroma_results_detailed(result, query_text=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Pinecone DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(\n",
    "\tname=\"compare-vector-db\"\n",
    ")  # created manually directly in the pinecone with 1536 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.upsert(vectors=[(\"0\", embeddings_array[0].tolist(), {\"text\": sentences[0]})])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Creating pinecone compatible record structure with custom metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i, (text, emb) in enumerate(zip(sentences, embeddings_array, strict=False)):\n",
    "\trecords.append(\n",
    "\t\t(\n",
    "\t\t\tf\"id_{i}\",\n",
    "\t\t\temb.tolist(),\n",
    "\t\t\t{\n",
    "\t\t\t\t\"text\": text,\n",
    "\t\t\t\t\"inserted_on\": str(datetime.now(UTC)),\n",
    "\t\t\t\t\"inserted_by\": \"batch_python\",\n",
    "\t\t\t},\n",
    "\t\t)\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.upsert(vectors=records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.fetch(ids=[\"id_17\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = queries[0]\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## Please notice we need to change query vector output to list to be used with pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = generate_embeddings(text=query).reshape(1, -1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = index.query(vector=query_vec, top_k=2, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pinecone_results(result, query_text=None, show_metadata=True):\n",
    "\t\"\"\"\n",
    "\tAdvanced Pinecone results parser with filtering options.\n",
    "\t\"\"\"\n",
    "\tif query_text:\n",
    "\t\tprint(f\"🔍 QUERY: '{query_text}'\")\n",
    "\t\tprint(\"=\" * 80)\n",
    "\n",
    "\tmatches = result.get(\"matches\", [])\n",
    "\tnamespace = result.get(\"namespace\", \"default\")\n",
    "\n",
    "\tif not matches:\n",
    "\t\tprint(\"❌ No matches found.\")\n",
    "\t\treturn\n",
    "\n",
    "\tprint(f\"📊 Found {len(matches)} results in namespace '{namespace}'\")\n",
    "\tprint(\"💡 Higher score = more similar (cosine similarity)\\n\")\n",
    "\n",
    "\tfor i, match in enumerate(matches):\n",
    "\t\tscore = match.get(\"score\", 0)\n",
    "\t\tdoc_id = match.get(\"id\", \"N/A\")\n",
    "\t\tmetadata = match.get(\"metadata\", {})\n",
    "\t\ttext = metadata.get(\"text\", \"No text available\")\n",
    "\n",
    "\t\t# Calculate similarity percentage\n",
    "\t\tsimilarity_pct = score * 100\n",
    "\n",
    "\t\t# Visual score indicator\n",
    "\t\tscore_bar = \"█\" * int(score * 20) + \"░\" * (20 - int(score * 20))\n",
    "\n",
    "\t\tprint(f\"🏆 RANK {i + 1}\")\n",
    "\t\tprint(f\"   📍 ID: {doc_id}\")\n",
    "\t\tprint(f\"   📈 Score: {score:.4f} ({similarity_pct:.1f}%)\")\n",
    "\t\tprint(f\"   📊 {score_bar}\")\n",
    "\t\tprint(f\"   📄 Text: {text}\")\n",
    "\n",
    "\t\tif show_metadata and metadata:\n",
    "\t\t\t# Exclude text from metadata display since we already show it\n",
    "\t\t\tother_metadata = {k: v for k, v in metadata.items() if k != \"text\"}\n",
    "\t\t\tif other_metadata:\n",
    "\t\t\t\tprint(\"   📋 Metadata:\")\n",
    "\t\t\t\tfor key, value in other_metadata.items():\n",
    "\t\t\t\t\tprint(f\"      • {key}: {value}\")\n",
    "\n",
    "\t\tprint(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_pinecone_results(result, query, show_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## WEAVIATE DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "\tcluster_url=WEAVIATE_REST_END_POINT,\n",
    "\tauth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate.classes as wvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_colleciton = client.collections.create(\n",
    "\tname=\"vectordb_compare\",\n",
    "\tvector_config=wvc.config.Configure.Vectors.self_provided(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### creating record structure expected by weaviate, also there is default metadata created on insert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for _i, (text, emb) in enumerate(zip(sentences, embeddings_array, strict=False)):\n",
    "\trecords.append(\n",
    "\t\twvc.data.DataObject(\n",
    "\t\t\tproperties={\n",
    "\t\t\t\t\"text\": text,\n",
    "\t\t\t\t\"inserted_on\": str(datetime.now(UTC)),\n",
    "\t\t\t\t\"inserted_by\": \"batch_python\",\n",
    "\t\t\t},\n",
    "\t\t\tvector=emb.tolist(),\n",
    "\t\t)\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_colleciton.data.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = queries[0]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = generate_embeddings(text=query).reshape(1, -1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = weaviate_colleciton.query.near_vector(\n",
    "\tnear_vector=query_vec[0],\n",
    "\tlimit=2,\n",
    "\treturn_metadata=wvc.query.MetadataQuery(certainty=True, distance=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in response.objects:\n",
    "\tprint(o.properties)\n",
    "\tprint(o.metadata.distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "## QDRANT DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_collection = \"vector-compare\"\n",
    "if qdrant_client.collection_exists(collection_name=qdrant_collection):\n",
    "\tqdrant_client.delete_collection(collection_name=qdrant_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "\tcollection_name=qdrant_collection,\n",
    "\tvectors_config=VectorParams(size=dimension, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "qdrant_client.upsert(\n",
    "\tcollection_name=qdrant_collection,\n",
    "\tpoints=[\n",
    "\t\tPointStruct(\n",
    "\t\t\tid=i,\n",
    "\t\t\tvector=emb.tolist(),\n",
    "\t\t\tpayload={\n",
    "\t\t\t\t\"text\": text,\n",
    "\t\t\t\t\"inserted_on\": str(datetime.now(UTC)),\n",
    "\t\t\t\t\"inserted_by\": \"batch_python\",\n",
    "\t\t\t},\n",
    "\t\t)\n",
    "\t\tfor i, (text, emb) in enumerate(zip(sentences, embeddings_array, strict=False))\n",
    "\t],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = queries[0]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = generate_embeddings(text=query).reshape(1, -1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qdrant_client.query_points(\n",
    "\tcollection_name=qdrant_collection,\n",
    "\tquery=query_vec[0],\n",
    "\tlimit=2,  # Return 2 closest points\n",
    "\twith_payload=True,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qdrant_response(response):\n",
    "\t\"\"\"\n",
    "\tParse and format Qdrant search response for user display\n",
    "\n",
    "\tArgs:\n",
    "\tresponse: QueryResponse object from Qdrant client search\n",
    "\n",
    "\tReturns:\n",
    "\tNone (prints formatted output)\n",
    "\t\"\"\"\n",
    "\tprint(f\"Found {len(response.points)} results:\\n\")\n",
    "\n",
    "\tfor i, point in enumerate(response.points, 1):\n",
    "\t\tprint(f\"Result {i}:\")\n",
    "\t\tprint(f\"  ID: {point.id}\")\n",
    "\t\tprint(f\"  Score: {point.score:.4f}\")\n",
    "\t\tprint(f\"  Text: {point.payload['text']}\")\n",
    "\t\tprint(f\"  Inserted on: {point.payload['inserted_on']}\")\n",
    "\t\tprint(f\"  Inserted by: {point.payload['inserted_by']}\")\n",
    "\t\tprint(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_qdrant_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-master-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
